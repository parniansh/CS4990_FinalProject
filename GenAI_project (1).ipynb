{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBr34SctmotX",
    "outputId": "fbcecbf4-c874-4fdd-dec7-73b63aa26a6a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "##%%\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 150\n",
    "learning_rate1 = 0.0002\n",
    "learning_rate2 = 0.004\n",
    "noise_dim = 100\n",
    "\n",
    "# import random\n",
    "# torch.manual_seed(420)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# augmentation (run once)\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "input_dir = '/content/sample_data/Orange/sub'\n",
    "output_dir = '/content/sample_data/Orange2/sub'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define individual augmentations\n",
    "augmentations = {\n",
    "    'resize': transforms.Resize((128, 128)),\n",
    "    'flip': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(p=1.0)\n",
    "    ]),\n",
    "    'rotate': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomRotation(15)\n",
    "    ]),\n",
    "    'color': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "       transforms.RandomVerticalFlip(p=1.0)\n",
    "    ]),\n",
    "    'affine': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "for fname in image_files:\n",
    "    img_path = os.path.join(input_dir, fname)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    for key, aug in augmentations.items():\n",
    "        aug_img = aug(img)\n",
    "        aug_img.save(os.path.join(output_dir, f\"{os.path.splitext(fname)[0]}_{key}.jpg\"))\n"
   ],
   "metadata": {
    "id": "IzqEhoyHdcbM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Load all data(run once)\n",
    "IMAGE_SIZE = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "import subprocess\n",
    "subprocess.run([\"ls\", \"-a\"])\n",
    "subprocess.run([\"rm\", \"-r\", \"/content/sample_data/Orange2/.ipynb_checkpoints\"])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "data_dir = '/content/sample_data/Orange2' \n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "BdiK7JczHQhb"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Vanilla model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, feature_maps=64, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "            nn.Linear(latent_dim, feature_maps * 8 * 4 * 4),\n",
    "\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (feature_maps * 8, 4, 4)),\n",
    "            nn.ConvTranspose2d(feature_maps * 8, feature_maps * 4, 4, 2, 1),\n",
    "\n",
    "            nn.BatchNorm2d(feature_maps * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(feature_maps * 4, feature_maps * 2, 4, 2, 1),\n",
    "\n",
    "            nn.BatchNorm2d(feature_maps * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(feature_maps * 2, feature_maps, 4, 2, 1),\n",
    "\n",
    "            nn.BatchNorm2d(feature_maps),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(feature_maps, channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feature_maps=64, channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(channels, feature_maps, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(feature_maps, feature_maps * 2, 4, 2, 1), \n",
    "            nn.BatchNorm2d(feature_maps * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(feature_maps * 2, feature_maps * 4, 4, 2, 1),  \n",
    "            nn.BatchNorm2d(feature_maps * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(feature_maps * 4, feature_maps * 8, 4, 2, 1),  \n",
    "            nn.BatchNorm2d(feature_maps * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(feature_maps * 8, 1, 4, 1, 0),             \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)  \n",
    "        return out.mean([2, 3]).view(-1, 1)\n",
    "\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate1)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate2)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "  for i, (images, _) in enumerate(train_loader):\n",
    "        real_images = images.to(device)\n",
    "        real_labels = torch.ones(images.size(0), 1, device=device)\n",
    "        fake_labels = torch.zeros(images.size(0), 1, device=device)\n",
    "\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(real_images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "\n",
    "        noise = torch.randn(images.size(0), noise_dim, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "  g_losses.append(g_loss.item())\n",
    "  d_losses.append(d_loss.item())\n",
    "\n",
    "  if (epoch+1) % 1 == 0: \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(train_loader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Save models\n",
    "torch.save(generator.state_dict(), 'Vgenerator.pth')\n",
    "torch.save(discriminator.state_dict(), 'Vdiscriminator.pth')\n",
    "\n"
   ],
   "metadata": {
    "id": "Z9_W0uIP4E2U",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "53bac992-7837-41b6-cea5-6034c87cd83e"
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/25], Batch [1/1], D Loss: 1.3643, G Loss: 5.0689\n",
      "Epoch [2/25], Batch [1/1], D Loss: 1.0695, G Loss: 6.1785\n",
      "Epoch [3/25], Batch [1/1], D Loss: 0.4430, G Loss: 7.4033\n",
      "Epoch [4/25], Batch [1/1], D Loss: 0.5335, G Loss: 6.8024\n",
      "Epoch [5/25], Batch [1/1], D Loss: 0.9647, G Loss: 7.3593\n",
      "Epoch [6/25], Batch [1/1], D Loss: 0.4257, G Loss: 9.4603\n",
      "Epoch [7/25], Batch [1/1], D Loss: 0.1512, G Loss: 10.0640\n",
      "Epoch [8/25], Batch [1/1], D Loss: 0.0545, G Loss: 9.4360\n",
      "Epoch [9/25], Batch [1/1], D Loss: 0.3931, G Loss: 11.5634\n",
      "Epoch [10/25], Batch [1/1], D Loss: 0.0460, G Loss: 12.3992\n",
      "Epoch [11/25], Batch [1/1], D Loss: 0.0484, G Loss: 12.1160\n",
      "Epoch [12/25], Batch [1/1], D Loss: 0.2441, G Loss: 9.9569\n",
      "Epoch [13/25], Batch [1/1], D Loss: 0.9752, G Loss: 13.2102\n",
      "Epoch [14/25], Batch [1/1], D Loss: 0.1124, G Loss: 14.9722\n",
      "Epoch [15/25], Batch [1/1], D Loss: 0.2780, G Loss: 15.7592\n",
      "Epoch [16/25], Batch [1/1], D Loss: 0.1681, G Loss: 15.7545\n",
      "Epoch [17/25], Batch [1/1], D Loss: 0.0274, G Loss: 15.0093\n",
      "Epoch [18/25], Batch [1/1], D Loss: 0.0049, G Loss: 12.8470\n",
      "Epoch [19/25], Batch [1/1], D Loss: 0.0226, G Loss: 8.6076\n",
      "Epoch [20/25], Batch [1/1], D Loss: 2.7759, G Loss: 13.1996\n",
      "Epoch [21/25], Batch [1/1], D Loss: 0.0086, G Loss: 15.7424\n",
      "Epoch [22/25], Batch [1/1], D Loss: 0.0418, G Loss: 17.0609\n",
      "Epoch [23/25], Batch [1/1], D Loss: 0.0211, G Loss: 17.7076\n",
      "Epoch [24/25], Batch [1/1], D Loss: 0.1083, G Loss: 17.9416\n",
      "Epoch [25/25], Batch [1/1], D Loss: 0.1050, G Loss: 17.8308\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# FastGAN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Generator\n",
    "class FastGANGenerator(nn.Module):\n",
    "    def __init__(self, z_dim=100, base_channels=64):\n",
    "        super(FastGANGenerator, self).__init__()\n",
    "        self.init_size = 4\n",
    "        self.l1 = nn.Linear(z_dim, base_channels * 8 * 4 * 4)\n",
    "\n",
    "        self.upsample_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(base_channels * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(base_channels * 8, base_channels * 4, 3, 1, 1),\n",
    "            nn.BatchNorm2d(base_channels * 4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 2, 3, 1, 1),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(base_channels * 2, base_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(base_channels, 3, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z).view(z.size(0), -1, self.init_size, self.init_size)\n",
    "        return self.upsample_blocks(out)\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "class FastGANDiscriminator(nn.Module):\n",
    "    def __init__(self, base_channels=64):\n",
    "        super(FastGANDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, base_channels, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(base_channels, base_channels * 2, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 4, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base_channels * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(base_channels * 4, 1, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "      out = self.model(img) \n",
    "      return out.mean([2, 3]).view(-1, 1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generator = FastGANGenerator().to(device)\n",
    "discriminator = FastGANDiscriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate1)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate2)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "  for i, (images, _) in enumerate(train_loader):\n",
    "        real_images = images.to(device)\n",
    "        real_labels = torch.ones(images.size(0), 1, device=device)\n",
    "        fake_labels = torch.zeros(images.size(0), 1, device=device)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(real_images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "\n",
    "        noise = torch.randn(images.size(0), noise_dim, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "  g_losses.append(g_loss.item())\n",
    "  d_losses.append(d_loss.item())\n",
    "\n",
    "  if (epoch+1) % 1 == 0:  \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(train_loader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Save models\n",
    "torch.save(generator.state_dict(), 'generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
    "\n",
    "##%%\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWGC78H0HX7n",
    "outputId": "9dfe9350-824d-4a72-d20c-99e4cbbb39c4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/150], Batch [2/2], D Loss: 2.0058, G Loss: 1.9846\n",
      "Epoch [2/150], Batch [2/2], D Loss: 1.2629, G Loss: 1.2797\n",
      "Epoch [3/150], Batch [2/2], D Loss: 0.9265, G Loss: 1.6693\n",
      "Epoch [4/150], Batch [2/2], D Loss: 1.4152, G Loss: 0.8537\n",
      "Epoch [5/150], Batch [2/2], D Loss: 1.8369, G Loss: 1.0045\n",
      "Epoch [6/150], Batch [2/2], D Loss: 1.6044, G Loss: 1.3242\n",
      "Epoch [7/150], Batch [2/2], D Loss: 1.4978, G Loss: 1.3415\n",
      "Epoch [8/150], Batch [2/2], D Loss: 1.2188, G Loss: 1.5669\n",
      "Epoch [9/150], Batch [2/2], D Loss: 1.1973, G Loss: 1.3606\n",
      "Epoch [10/150], Batch [2/2], D Loss: 1.2199, G Loss: 1.1647\n",
      "Epoch [11/150], Batch [2/2], D Loss: 1.0928, G Loss: 1.1026\n",
      "Epoch [12/150], Batch [2/2], D Loss: 0.9621, G Loss: 1.1065\n",
      "Epoch [13/150], Batch [2/2], D Loss: 0.8848, G Loss: 1.1755\n",
      "Epoch [14/150], Batch [2/2], D Loss: 0.7405, G Loss: 1.3248\n",
      "Epoch [15/150], Batch [2/2], D Loss: 0.7953, G Loss: 1.3476\n",
      "Epoch [16/150], Batch [2/2], D Loss: 0.8604, G Loss: 1.3012\n",
      "Epoch [17/150], Batch [2/2], D Loss: 0.9669, G Loss: 1.1741\n",
      "Epoch [18/150], Batch [2/2], D Loss: 0.9416, G Loss: 1.0964\n",
      "Epoch [19/150], Batch [2/2], D Loss: 0.7916, G Loss: 1.1781\n",
      "Epoch [20/150], Batch [2/2], D Loss: 0.7605, G Loss: 1.3235\n",
      "Epoch [21/150], Batch [2/2], D Loss: 0.6922, G Loss: 1.6638\n",
      "Epoch [22/150], Batch [2/2], D Loss: 0.8822, G Loss: 1.3292\n",
      "Epoch [23/150], Batch [2/2], D Loss: 0.9871, G Loss: 0.9963\n",
      "Epoch [24/150], Batch [2/2], D Loss: 1.4563, G Loss: 0.7686\n",
      "Epoch [25/150], Batch [2/2], D Loss: 2.1921, G Loss: 0.6855\n",
      "Epoch [26/150], Batch [2/2], D Loss: 1.4711, G Loss: 0.7573\n",
      "Epoch [27/150], Batch [2/2], D Loss: 1.4377, G Loss: 0.7950\n",
      "Epoch [28/150], Batch [2/2], D Loss: 1.3299, G Loss: 0.7925\n",
      "Epoch [29/150], Batch [2/2], D Loss: 1.2277, G Loss: 0.9633\n",
      "Epoch [30/150], Batch [2/2], D Loss: 1.2495, G Loss: 0.9557\n",
      "Epoch [31/150], Batch [2/2], D Loss: 1.3707, G Loss: 0.8295\n",
      "Epoch [32/150], Batch [2/2], D Loss: 1.3303, G Loss: 0.7510\n",
      "Epoch [33/150], Batch [2/2], D Loss: 1.3798, G Loss: 0.6911\n",
      "Epoch [34/150], Batch [2/2], D Loss: 1.4485, G Loss: 0.6392\n",
      "Epoch [35/150], Batch [2/2], D Loss: 1.4536, G Loss: 0.5472\n",
      "Epoch [36/150], Batch [2/2], D Loss: 1.5713, G Loss: 0.4495\n",
      "Epoch [37/150], Batch [2/2], D Loss: 1.7327, G Loss: 0.3750\n",
      "Epoch [38/150], Batch [2/2], D Loss: 1.8724, G Loss: 0.3423\n",
      "Epoch [39/150], Batch [2/2], D Loss: 1.7594, G Loss: 0.3835\n",
      "Epoch [40/150], Batch [2/2], D Loss: 1.5555, G Loss: 0.4549\n",
      "Epoch [41/150], Batch [2/2], D Loss: 1.4463, G Loss: 0.5434\n",
      "Epoch [42/150], Batch [2/2], D Loss: 1.3223, G Loss: 0.6436\n",
      "Epoch [43/150], Batch [2/2], D Loss: 1.1831, G Loss: 0.7689\n",
      "Epoch [44/150], Batch [2/2], D Loss: 1.0097, G Loss: 0.9389\n",
      "Epoch [45/150], Batch [2/2], D Loss: 0.8750, G Loss: 1.1275\n",
      "Epoch [46/150], Batch [2/2], D Loss: 0.7847, G Loss: 1.3030\n",
      "Epoch [47/150], Batch [2/2], D Loss: 0.6663, G Loss: 1.3969\n",
      "Epoch [48/150], Batch [2/2], D Loss: 0.6149, G Loss: 1.5323\n",
      "Epoch [49/150], Batch [2/2], D Loss: 0.5765, G Loss: 1.6250\n",
      "Epoch [50/150], Batch [2/2], D Loss: 0.6531, G Loss: 1.5257\n",
      "Epoch [51/150], Batch [2/2], D Loss: 0.7323, G Loss: 1.2982\n",
      "Epoch [52/150], Batch [2/2], D Loss: 0.7513, G Loss: 1.1995\n",
      "Epoch [53/150], Batch [2/2], D Loss: 0.7460, G Loss: 1.1569\n",
      "Epoch [54/150], Batch [2/2], D Loss: 0.7309, G Loss: 1.3306\n",
      "Epoch [55/150], Batch [2/2], D Loss: 0.6649, G Loss: 1.4669\n",
      "Epoch [56/150], Batch [2/2], D Loss: 0.6732, G Loss: 1.8141\n",
      "Epoch [57/150], Batch [2/2], D Loss: 0.6739, G Loss: 1.7290\n",
      "Epoch [58/150], Batch [2/2], D Loss: 0.7220, G Loss: 1.5354\n",
      "Epoch [59/150], Batch [2/2], D Loss: 0.8262, G Loss: 1.3542\n",
      "Epoch [60/150], Batch [2/2], D Loss: 0.8477, G Loss: 1.2481\n",
      "Epoch [61/150], Batch [2/2], D Loss: 0.9978, G Loss: 0.9752\n",
      "Epoch [62/150], Batch [2/2], D Loss: 1.0748, G Loss: 0.7922\n",
      "Epoch [63/150], Batch [2/2], D Loss: 1.1842, G Loss: 0.6951\n",
      "Epoch [64/150], Batch [2/2], D Loss: 1.3095, G Loss: 0.5804\n",
      "Epoch [65/150], Batch [2/2], D Loss: 1.4194, G Loss: 0.5401\n",
      "Epoch [66/150], Batch [2/2], D Loss: 1.4239, G Loss: 0.4838\n",
      "Epoch [67/150], Batch [2/2], D Loss: 1.5046, G Loss: 0.4661\n",
      "Epoch [68/150], Batch [2/2], D Loss: 1.6309, G Loss: 0.4360\n",
      "Epoch [69/150], Batch [2/2], D Loss: 1.7108, G Loss: 0.3789\n",
      "Epoch [70/150], Batch [2/2], D Loss: 1.7927, G Loss: 0.3592\n",
      "Epoch [71/150], Batch [2/2], D Loss: 1.9075, G Loss: 0.3139\n",
      "Epoch [72/150], Batch [2/2], D Loss: 1.9933, G Loss: 0.2923\n",
      "Epoch [73/150], Batch [2/2], D Loss: 2.0359, G Loss: 0.2778\n",
      "Epoch [74/150], Batch [2/2], D Loss: 2.2057, G Loss: 0.2380\n",
      "Epoch [75/150], Batch [2/2], D Loss: 2.2439, G Loss: 0.2126\n",
      "Epoch [76/150], Batch [2/2], D Loss: 2.4069, G Loss: 0.1938\n",
      "Epoch [77/150], Batch [2/2], D Loss: 2.5006, G Loss: 0.1804\n",
      "Epoch [78/150], Batch [2/2], D Loss: 2.6756, G Loss: 0.1481\n",
      "Epoch [79/150], Batch [2/2], D Loss: 2.8106, G Loss: 0.1257\n",
      "Epoch [80/150], Batch [2/2], D Loss: 3.0451, G Loss: 0.1091\n",
      "Epoch [81/150], Batch [2/2], D Loss: 3.1864, G Loss: 0.1018\n",
      "Epoch [82/150], Batch [2/2], D Loss: 3.7444, G Loss: 0.0809\n",
      "Epoch [83/150], Batch [2/2], D Loss: 4.1212, G Loss: 0.0722\n",
      "Epoch [84/150], Batch [2/2], D Loss: 3.3288, G Loss: 0.1428\n",
      "Epoch [85/150], Batch [2/2], D Loss: 3.4958, G Loss: 0.2380\n",
      "Epoch [86/150], Batch [2/2], D Loss: 3.5295, G Loss: 0.3022\n",
      "Epoch [87/150], Batch [2/2], D Loss: 3.4586, G Loss: 0.3715\n",
      "Epoch [88/150], Batch [2/2], D Loss: 2.9374, G Loss: 0.4479\n",
      "Epoch [89/150], Batch [2/2], D Loss: 2.9184, G Loss: 0.5124\n",
      "Epoch [90/150], Batch [2/2], D Loss: 2.7065, G Loss: 0.5322\n",
      "Epoch [91/150], Batch [2/2], D Loss: 2.5720, G Loss: 0.5487\n",
      "Epoch [92/150], Batch [2/2], D Loss: 3.1130, G Loss: 0.5673\n",
      "Epoch [93/150], Batch [2/2], D Loss: 2.5082, G Loss: 0.5901\n",
      "Epoch [94/150], Batch [2/2], D Loss: 2.9363, G Loss: 0.6025\n",
      "Epoch [95/150], Batch [2/2], D Loss: 2.9465, G Loss: 0.6015\n",
      "Epoch [96/150], Batch [2/2], D Loss: 2.9385, G Loss: 0.6395\n",
      "Epoch [97/150], Batch [2/2], D Loss: 2.6102, G Loss: 0.6434\n",
      "Epoch [98/150], Batch [2/2], D Loss: 2.7855, G Loss: 0.6318\n",
      "Epoch [99/150], Batch [2/2], D Loss: 3.0848, G Loss: 0.6220\n",
      "Epoch [100/150], Batch [2/2], D Loss: 2.7408, G Loss: 0.6251\n",
      "Epoch [101/150], Batch [2/2], D Loss: 3.0988, G Loss: 0.6059\n",
      "Epoch [102/150], Batch [2/2], D Loss: 3.2917, G Loss: 0.5963\n",
      "Epoch [103/150], Batch [2/2], D Loss: 2.7079, G Loss: 0.5982\n",
      "Epoch [104/150], Batch [2/2], D Loss: 3.6368, G Loss: 0.5816\n",
      "Epoch [105/150], Batch [2/2], D Loss: 2.8808, G Loss: 0.5782\n",
      "Epoch [106/150], Batch [2/2], D Loss: 3.0216, G Loss: 0.5661\n",
      "Epoch [107/150], Batch [2/2], D Loss: 4.7417, G Loss: 0.5769\n",
      "Epoch [108/150], Batch [2/2], D Loss: 2.8371, G Loss: 0.5481\n",
      "Epoch [109/150], Batch [2/2], D Loss: 3.5282, G Loss: 0.5430\n",
      "Epoch [110/150], Batch [2/2], D Loss: 4.0825, G Loss: 0.5158\n",
      "Epoch [111/150], Batch [2/2], D Loss: 3.3366, G Loss: 0.5366\n",
      "Epoch [112/150], Batch [2/2], D Loss: 3.4352, G Loss: 0.5163\n",
      "Epoch [113/150], Batch [2/2], D Loss: 4.5091, G Loss: 0.4990\n",
      "Epoch [114/150], Batch [2/2], D Loss: 3.6234, G Loss: 0.5060\n",
      "Epoch [115/150], Batch [2/2], D Loss: 4.0827, G Loss: 0.4917\n",
      "Epoch [116/150], Batch [2/2], D Loss: 2.9301, G Loss: 0.4813\n",
      "Epoch [117/150], Batch [2/2], D Loss: 3.5830, G Loss: 0.4776\n",
      "Epoch [118/150], Batch [2/2], D Loss: 3.6190, G Loss: 0.4616\n",
      "Epoch [119/150], Batch [2/2], D Loss: 3.2467, G Loss: 0.4574\n",
      "Epoch [120/150], Batch [2/2], D Loss: 3.1865, G Loss: 0.4634\n",
      "Epoch [121/150], Batch [2/2], D Loss: 3.2873, G Loss: 0.4564\n",
      "Epoch [122/150], Batch [2/2], D Loss: 3.6983, G Loss: 0.4231\n",
      "Epoch [123/150], Batch [2/2], D Loss: 3.5123, G Loss: 0.4308\n",
      "Epoch [124/150], Batch [2/2], D Loss: 3.0319, G Loss: 0.4177\n",
      "Epoch [125/150], Batch [2/2], D Loss: 3.7909, G Loss: 0.4300\n",
      "Epoch [126/150], Batch [2/2], D Loss: 3.1901, G Loss: 0.4008\n",
      "Epoch [127/150], Batch [2/2], D Loss: 3.5495, G Loss: 0.3980\n",
      "Epoch [128/150], Batch [2/2], D Loss: 3.4946, G Loss: 0.3694\n",
      "Epoch [129/150], Batch [2/2], D Loss: 3.2375, G Loss: 0.3762\n",
      "Epoch [130/150], Batch [2/2], D Loss: 3.3142, G Loss: 0.3710\n",
      "Epoch [131/150], Batch [2/2], D Loss: 3.2675, G Loss: 0.3535\n",
      "Epoch [132/150], Batch [2/2], D Loss: 3.3963, G Loss: 0.3501\n",
      "Epoch [133/150], Batch [2/2], D Loss: 4.3995, G Loss: 0.3333\n",
      "Epoch [134/150], Batch [2/2], D Loss: 4.0661, G Loss: 0.3526\n",
      "Epoch [135/150], Batch [2/2], D Loss: 3.8813, G Loss: 0.3123\n",
      "Epoch [136/150], Batch [2/2], D Loss: 3.6203, G Loss: 0.3169\n",
      "Epoch [137/150], Batch [2/2], D Loss: 3.2623, G Loss: 0.3249\n",
      "Epoch [138/150], Batch [2/2], D Loss: 3.5141, G Loss: 0.3062\n",
      "Epoch [139/150], Batch [2/2], D Loss: 3.4019, G Loss: 0.2903\n",
      "Epoch [140/150], Batch [2/2], D Loss: 3.9129, G Loss: 0.2817\n",
      "Epoch [141/150], Batch [2/2], D Loss: 3.4985, G Loss: 0.2754\n",
      "Epoch [142/150], Batch [2/2], D Loss: 3.2978, G Loss: 0.2793\n",
      "Epoch [143/150], Batch [2/2], D Loss: 3.4178, G Loss: 0.2700\n",
      "Epoch [144/150], Batch [2/2], D Loss: 4.4059, G Loss: 0.2690\n",
      "Epoch [145/150], Batch [2/2], D Loss: 4.1200, G Loss: 0.2693\n",
      "Epoch [146/150], Batch [2/2], D Loss: 3.5096, G Loss: 0.2505\n",
      "Epoch [147/150], Batch [2/2], D Loss: 3.6485, G Loss: 0.2565\n",
      "Epoch [148/150], Batch [2/2], D Loss: 4.6495, G Loss: 0.2533\n",
      "Epoch [149/150], Batch [2/2], D Loss: 3.4348, G Loss: 0.2500\n",
      "Epoch [150/150], Batch [2/2], D Loss: 3.5729, G Loss: 0.2404\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Generate image\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1, noise_dim).to(device)\n",
    "    generated = generator(z).detach().cpu()  # shape: (1, C, H, W)\n",
    "\n",
    "# Denormalize from [-1, 1] to [0, 1]\n",
    "generated = (generated + 1) / 2\n",
    "\n",
    "# Convert to NumPy image\n",
    "img = generated.squeeze().numpy()  # shape: (C, H, W) or (H, W)\n",
    "\n",
    "# Plot\n",
    "if img.ndim == 3:  # RGB\n",
    "    img = np.transpose(img, (1, 2, 0))  # (H, W, C)\n",
    "\n",
    "plt.imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "FLjdCEwEzJYS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#loss plot\n",
    "print(g_losses)\n",
    "epoch = range(1, len(g_losses) + 1)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epoch, g_losses, label='Generator Loss')\n",
    "plt.plot(epoch, d_losses, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAN Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "iGfJWyPGHx68"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
